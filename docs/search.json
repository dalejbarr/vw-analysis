[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducibly Analysing Visual-World Eyetracking Data",
    "section": "",
    "text": "For this workshop, we will be reproducing data from a study by Weighall et al. (2017) on the role of sleep in learning novel words (lexical consolidation).\nUnlike in the Weighall et al. article, to simplify presentation, this book will focus on the comparison between adult and child participants in the processing of existing “lexical competitors”, as in the words “candy” and “candle”.\n\n\nYou will need to download and extract data-raw.zip into your working directory.\nAppendix A has a figure showing the structure of the data. You will probably need to refer back to this figure many times as you work through the exercises.\n\n\n\n\nWeighall, AR, Lisa-Marie Henderson, DJ Barr, Scott Ashley Cairney, and Mark Gareth Gaskell. 2017. “Eye-Tracking the Time-Course of Novel Word Learning and Lexical Competition in Adults and Children.” Brain and Language 167: 13–27."
  },
  {
    "objectID": "preprocessing_1.html",
    "href": "preprocessing_1.html",
    "title": "1  Import, epoching, and time-alignment",
    "section": "",
    "text": "The overall task here is to scrape out the data we want to use from each trial (epoching) and align the frame counters for all trials to the disambiguation point for the particular audio stimulus that was played on that trial (time-alignment). In other words, the disambiguation point should be the temporal “origin” (zero point) for the timeline on each trial."
  },
  {
    "objectID": "preprocessing_1.html#data-import",
    "href": "preprocessing_1.html#data-import",
    "title": "1  Import, epoching, and time-alignment",
    "section": "1.1 Data import",
    "text": "1.1 Data import\nFor the first part of pre-processing, we will load the eye data into our R session using functions from the {readr} package, which is one of many packages that is part of the {tidyverse} meta-package. The .gazedata files from the Tobii eyetracking system are in .tsv or Tab Separated Values format, for which we use read_tsv().\nBefore we can perform epoching and time-alignment, we have to import and clean up the .gazedata files. These are 42 adult data files and 41 child data files located in the adult and child subdirectories of data-raw/. These files follow the naming convention data-raw/adult/sub_XXX.gazedata and data-raw/child/sub_XXX.gazedata where the XXX part of the filename the unique integer identifying each subject, which corresponds to sub_id in the subjects table.\nThe raw gazedata files include a lot of unnecessary information. We’ll need to scrape out the data that we need and convert the XXX value from the filename into a sub_id variable in the resulting table. The source files have the format below.\n\n\n\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\n\nID\nint\narbitrary value uniquely identifying each frame within subject\n\n\nTETTime\ndbl\n(ignored)\n\n\nRTTime\nint\n(ignored)\n\n\nCursorX\nint\nhorizontal point of gaze in pixels\n\n\nCursorY\nint\nvertical point of gaze in pixels\n\n\nTimestampSec\nint\ntimestamp in seconds\n\n\nTimestampMicrosec\nint\nmillisecond portion of timestamp (cycles around)\n\n\nXGazePosLeftEye\ndbl\n(ignored)\n\n\nYGazePosLeftEye\ndbl\n(ignored)\n\n\nXCameraPosLeftEye\ndbl\n(ignored)\n\n\nYCameraPosLeftEye\ndbl\n(ignored)\n\n\nDiameterPupilLeftEye\ndbl\n(ignored)\n\n\nDistanceLeftEye\ndbl\n(ignored)\n\n\nValidityLeftEye\nint\n(ignored)\n\n\nXGazePosRightEye\ndbl\n(ignored)\n\n\nYGazePosRightEye\ndbl\n(ignored)\n\n\nXCameraPosRightEye\ndbl\n(ignored)\n\n\nYCameraPosRightEye\ndbl\n(ignored)\n\n\nDiameterPupilRightEye\ndbl\n(ignored)\n\n\nDistanceRightEye\ndbl\n(ignored)\n\n\nValidityRightEye\nint\n(ignored)\n\n\nTrialId\nint\narbitrary value uniquely identifying each trial within a subject (same as t_id)\n\n\nUserDefined_1\nchr\nphase of the trial (Fixation, Preview, StimSlide)\n\n\n\n\n\n\n1.1.1 Activity: One Subject\nRead in the Tobii eyetracking data for a single subject from the datafile data-raw/adult/sub_003.gazedata, and convert it to the format below.\n\n\n# A tibble: 16,658 × 7\n   sub_id  t_id  f_id         sec     x     y phase  \n    <int> <int> <int>       <dbl> <int> <int> <chr>  \n 1      3     1   145 1317141127.   666   521 Preview\n 2      3     1   146 1317141127.   649   442 Preview\n 3      3     1   147 1317141127.   618   507 Preview\n 4      3     1   148 1317141127.   645   471 Preview\n 5      3     1   149 1317141127.   632   471 Preview\n 6      3     1   150 1317141127.   645   536 Preview\n 7      3     1   151 1317141127.   651   474 Preview\n 8      3     1   152 1317141127.   643   541 Preview\n 9      3     1   153 1317141127.   628   581 Preview\n10      3     1   154 1317141127.   643   532 Preview\n# … with 16,648 more rows\n\n\nHere, we have renamed TrialId to t_id, which is the name it takes throughout the rest of the database. We have also renamed CursorX and CursorY to x and y respectively. We have also renamed ID to f_id (frame id) and UserDefined_1 to phase. We also exclude any frames from the phase where UserDefined_1 == \"Fixation\", because these frames are not informative, and doing so reduces the size of the data we need to import.\n\n\n\n\n\n\nHint: Importing only those columns you need\n\n\n\n\n\nUse the col_types argument to read_tsv() and the cols_only() specification.\nFor instance, something like:\n\nread_tsv(\"data-raw/adult/sub_003.gazedata\",\n         col_types = cols_only(ID = col_integer(),\n                              # [..etc]\n                              ),\n         #.. other args to read_tsv,\n         )\n\nType ?readr::cols_only in the console to learn more about specifying columns during data import.\n\n\n\n\n\n\n\n\n\nHint: Extracting the subject id number\n\n\n\n\n\nYou can use the id argument to read_tsv() to specify the name of a variable in the resulting data frame that has the filename as its value.\nYou can then create a new variable using mutate() that extracts the XXX substring (positions 20-22 of the string) and then converts it to an integer.\n\nread_tsv(\"data-raw/adult/sub_003.gazedata\",\n         id = \"filename\",\n         # other args to read_tsv()...\n         ) %>%\n  mutate(sub_id = substr(filename, 20, 22) %>% as.integer()) # %>%\n  ## rest of your pipeline..\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(\"tidyverse\")\n\n## make sure that your working directory is properly set!\n\nread_tsv(\"data-raw/adult/sub_003.gazedata\",\n         col_types = cols_only(ID = col_integer(),\n                               TrialId = col_integer(),\n                               CursorX = col_integer(),\n                               CursorY = col_integer(),\n                               TimestampSec = col_integer(),\n                               TimestampMicrosec = col_integer(),\n                               UserDefined_1 = col_character()),\n         id = \"filename\") %>%\n  ## convert XXX to sub_id\n  mutate(sub_id = substr(filename, 20, 22) %>% as.integer(),\n         sec = TimestampSec + TimestampMicrosec / 1000000) %>%\n  select(sub_id, t_id = TrialId, f_id = ID,\n         sec, x = CursorX, y = CursorY,\n         phase = UserDefined_1) %>%\n  filter(phase != \"Fixation\")\n\n\n\n\n\n\n1.1.2 Activity: All Subjects\nNow adapt the code that you wrote above to load in all 83 into a single table, which should have the same format as for the data you imported for subject 3 above.\n\n\n\n\n\n\nTip\n\n\n\n\n\nThe readr functions like read_tsv() make it easy to read in multiple files. All you need to do is to provide a vector of filenames as the first argument.\nFor example, read_tsv(c(\"file1.tsv\", \"file2.tsv\")) will read both file1.tsv and file2.tsv and bind together the rows imported from both files in the result.\n\n\n\n\n\n\n\n\n\nHint: How do I get a vector of all the files in a directory?\n\n\n\n\n\nThe dir() function for base R can be used to list files. Examples:\n\ndir(\"data-raw\")\n\n[1] \"adult\"              \"child\"              \"locations.csv\"     \n[4] \"screens.csv\"        \"speech-timings.csv\" \"stimuli.csv\"       \n[7] \"subjects.csv\"       \"trials.csv\"        \n\n\n\nadults <- dir(\"data-raw/adult\", full.names = TRUE)\n\nadults\n\n [1] \"data-raw/adult/sub_001.gazedata\" \"data-raw/adult/sub_002.gazedata\"\n [3] \"data-raw/adult/sub_003.gazedata\" \"data-raw/adult/sub_004.gazedata\"\n [5] \"data-raw/adult/sub_005.gazedata\" \"data-raw/adult/sub_006.gazedata\"\n [7] \"data-raw/adult/sub_007.gazedata\" \"data-raw/adult/sub_008.gazedata\"\n [9] \"data-raw/adult/sub_009.gazedata\" \"data-raw/adult/sub_010.gazedata\"\n[11] \"data-raw/adult/sub_011.gazedata\" \"data-raw/adult/sub_012.gazedata\"\n[13] \"data-raw/adult/sub_013.gazedata\" \"data-raw/adult/sub_014.gazedata\"\n[15] \"data-raw/adult/sub_015.gazedata\" \"data-raw/adult/sub_016.gazedata\"\n[17] \"data-raw/adult/sub_017.gazedata\" \"data-raw/adult/sub_018.gazedata\"\n[19] \"data-raw/adult/sub_019.gazedata\" \"data-raw/adult/sub_020.gazedata\"\n[21] \"data-raw/adult/sub_021.gazedata\" \"data-raw/adult/sub_022.gazedata\"\n[23] \"data-raw/adult/sub_023.gazedata\" \"data-raw/adult/sub_024.gazedata\"\n[25] \"data-raw/adult/sub_025.gazedata\" \"data-raw/adult/sub_026.gazedata\"\n[27] \"data-raw/adult/sub_027.gazedata\" \"data-raw/adult/sub_028.gazedata\"\n[29] \"data-raw/adult/sub_029.gazedata\" \"data-raw/adult/sub_030.gazedata\"\n[31] \"data-raw/adult/sub_031.gazedata\" \"data-raw/adult/sub_032.gazedata\"\n[33] \"data-raw/adult/sub_033.gazedata\" \"data-raw/adult/sub_034.gazedata\"\n[35] \"data-raw/adult/sub_035.gazedata\" \"data-raw/adult/sub_036.gazedata\"\n[37] \"data-raw/adult/sub_037.gazedata\" \"data-raw/adult/sub_039.gazedata\"\n[39] \"data-raw/adult/sub_040.gazedata\" \"data-raw/adult/sub_041.gazedata\"\n[41] \"data-raw/adult/sub_042.gazedata\" \"data-raw/adult/sub_043.gazedata\"\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## get .gazedata filenames\nadults <- dir(\"data-raw/adult\", full.names = TRUE)\nchildren <- dir(\"data-raw/child\", full.names = TRUE)\n\nedat <- read_tsv(c(adults, children),\n                 col_types = cols_only(ID = col_integer(),\n                                       TrialId = col_integer(),\n                                       CursorX = col_integer(),\n                                       CursorY = col_integer(),\n                                       TimestampSec = col_integer(),\n                                       TimestampMicrosec = col_integer(),\n                                       UserDefined_1 = col_character()),\n                 id = \"filename\") %>%\n  mutate(sub_id = substr(filename, 20, 22) %>% as.integer(),\n         sec = TimestampSec + TimestampMicrosec / 1000000) %>%\n  select(sub_id, t_id = TrialId, f_id = ID,\n         sec, x = CursorX, y = CursorY,\n         phase = UserDefined_1) %>%\n  filter(phase != \"Fixation\")\n\nedat\n\n# A tibble: 1,899,013 × 7\n   sub_id  t_id  f_id         sec     x     y phase  \n    <int> <int> <int>       <dbl> <int> <int> <chr>  \n 1      1     1   272 1317113393.   628   523 Preview\n 2      1     1   273 1317113393.   634   529 Preview\n 3      1     1   274 1317113393.   633   519 Preview\n 4      1     1   275 1317113393.   644   531 Preview\n 5      1     1   276 1317113393.   637   520 Preview\n 6      1     1   277 1317113393.   635   515 Preview\n 7      1     1   278 1317113393.   636   519 Preview\n 8      1     1   279 1317113393.   638   518 Preview\n 9      1     1   280 1317113393.   642   519 Preview\n10      1     1   281 1317113393.   638   518 Preview\n# … with 1,899,003 more rows"
  },
  {
    "objectID": "preprocessing_1.html#epoching-and-time-alignment",
    "href": "preprocessing_1.html#epoching-and-time-alignment",
    "title": "1  Import, epoching, and time-alignment",
    "section": "1.2 Epoching and time-alignment",
    "text": "1.2 Epoching and time-alignment\nThe Tobii eyetracker recorded data at a rate of 60 Hertz (i.e., 60 frames per second, or one frame every 1/60th of a second.) For each trial, the frame counter (ID, which we renamed to f_id) starts at 1 and increments every frame. This is not very useful because we need to know when certain stimulus events occurred, and these will take place at a different frame number for every trial, depending on the timing of the speech events of the stimulus for that trial. We need to re-define the ‘origin’ of the eye-tracking data. In this study, we used the ‘disambiguation point’, which is the point in the word where the signal distinguishes between two competing lexical items (e.g., candy and candle).\n\nAs the above figure shows, each trial had three phases, a Fixation, Preview, and StimSlide phase, which are indexed by the variable phase. Playback of a soundfile with a pre-recorded speech stimulus began simultaneously with the onset of the StimSlide phase.\nFor each trial (uniquely identified by sub_id and t_id), we are going to need to do two things to time-align the eye data to the disambiguation point.\n\nFind out what sound was played and the timing of the disambiguation point within that soundfile, as measured from the start of the file.\nFigure out the frame number corresponding to the start of the StimSlide phase and then adjust by the amount calculated in the previous step.\n\n\n1.2.1 Activity: Disambiguation Point\nCreate the table below from the raw data, which has information about the onset of the disambiguation point for each trial. Store the table as origin_adj.\nYou may wish to consult Appendix A to see what tables the values in the table below have been are drawn from. You’ll need to import these tables into your session. All of these tables have the extension .csv, which indicates they are in Comma Separated Values format. The ideal way to import these files is to use read_csv() from the {readr} package.\n\n\n# A tibble: 5,644 × 4\n   sub_id  t_id sound          disambig_point\n    <int> <int> <chr>                   <int>\n 1      1     1 Tpelican.wav             1171\n 2      1     2 Tpumpkin.wav             1079\n 3      1     3 pencil.wav                810\n 4      1     4 paddle.wav                881\n 5      1     6 Tbalcony.wav             1012\n 6      1     7 Tnapkin.wav              1069\n 7      1    11 Tflamingo.wav            1150\n 8      1    13 Tangel.wav               1036\n 9      1    14 Tparachute.wav           1046\n10      1    16 Tmushroom.wav            1062\n# … with 5,634 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntrials <- read_csv(\"data-raw/trials.csv\",\n                   col_types = \"iiiiii\")\n\nstimuli <- read_csv(\"data-raw/stimuli.csv\",\n                    col_types = \"iiciccc\")\n\nspeech <- read_csv(\"data-raw/speech-timings.csv\",\n                   col_types = \"ciii\")\n\norigin_adj <- trials %>%\n  inner_join(stimuli, \"iv_id\") %>% # to get `sound`\n  select(sub_id, t_id, sound) %>% \n  inner_join(speech, \"sound\") %>% # to get the timings\n  select(-article, -noun)\n\n\n\n\n\n\n1.2.2 Activity: Onset of StimSlide\nNow let’s do part 2, where we find the value of f_id for the first frame of eyedata for each trial following the onset of the StimSlide phase. We should have a table that looks like the one below, with one row for each trial, and where f_ss is the value of f_id for the earliest frame in the StimSlide phase.\n\n\n# A tibble: 7,385 × 3\n   sub_id  t_id  f_ss\n    <int> <int> <int>\n 1      1     1   338\n 2      1     2   729\n 3      1     3  1124\n 4      1     4  1443\n 5      1     5  1795\n 6      1     6  2300\n 7      1     7  2593\n 8      1     8  3348\n 9      1     9  3874\n10      1    10  4331\n# … with 7,375 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## figure out the f_id for the earliest StimSlide frame\norigin_frames <- edat %>% \n  filter(phase == \"StimSlide\") %>%\n  group_by(sub_id, t_id) %>%\n  summarise(f_ss = min(f_id),\n            .groups = \"drop\")\n\norigin_frames\n\n\n\n\n\n\n1.2.3 Activity: Combine origins\nNow that we have the first frame of StimSlide and the adjustment we have to make in milliseconds for the disambiguation point, combine the tables and calculate f_z, which will represent the “zero points” in frames for each trial. Store the resulting table in origins.\n\n\n# A tibble: 5,643 × 5\n   sub_id  t_id  f_ss disambig_point   f_z\n    <int> <int> <int>          <int> <int>\n 1      1     1   338           1171   408\n 2      1     2   729           1079   794\n 3      1     3  1124            810  1173\n 4      1     4  1443            881  1496\n 5      1     6  2300           1012  2361\n 6      1     7  2593           1069  2657\n 7      1    11  4699           1150  4768\n 8      1    13  5395           1036  5457\n 9      1    14  5893           1046  5956\n10      1    16  6811           1062  6875\n# … with 5,633 more rows\n\n\n\n\n\n\n\n\nHint: How to convert milliseconds to frames of eye data\n\n\n\n\n\nThere are 60 frames per second, so 60 frames per 1000 milliseconds.\nSo to convert from milliseconds to frames:\nf_z = 60 * ms / 1000\nFor example, if you have 500 ms, then 60 * 500 / 1000 = 30.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\norigins <- origin_frames %>%\n  inner_join(origin_adj, c(\"sub_id\", \"t_id\")) %>%\n  mutate(f_z = round(f_ss + 60 * disambig_point / 1000) %>%\n           as.integer()) %>%\n  select(-sound)\n\n\n\n\n\n\n1.2.4 Activity: Time-align\nNow we’re ready to calculate a new frame index on our eye data (edat), f_c, which is centered on the zero point, f_z. The resulting table should be called epdat and have the following structure.\n\n\n# A tibble: 1,341,405 × 7\n   sub_id  t_id  f_id   f_z   f_c     x     y\n    <int> <int> <int> <int> <int> <int> <int>\n 1      1     1   272   408  -136   628   523\n 2      1     1   273   408  -135   634   529\n 3      1     1   274   408  -134   633   519\n 4      1     1   275   408  -133   644   531\n 5      1     1   276   408  -132   637   520\n 6      1     1   277   408  -131   635   515\n 7      1     1   278   408  -130   636   519\n 8      1     1   279   408  -129   638   518\n 9      1     1   280   408  -128   642   519\n10      1     1   281   408  -127   638   518\n# … with 1,341,395 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nepdat <- edat %>%\n  inner_join(origins, c(\"sub_id\", \"t_id\")) %>%\n  mutate(f_c = f_id - f_z) %>%\n  select(sub_id, t_id, f_id, f_z, f_c, x, y)"
  },
  {
    "objectID": "preprocessing_1.html#save-the-data",
    "href": "preprocessing_1.html#save-the-data",
    "title": "1  Import, epoching, and time-alignment",
    "section": "1.3 Save the data",
    "text": "1.3 Save the data\nWe’ve reached a stopping point. We’ll want to save the epoched data so that we can use that as our starting point for the next preprocessing stage. We’ll remove the variables f_id and f_z because we no longer need them. We’ll also keep 1.5 seconds (90 frames) before and after the disambiguation point for each trial.\n\n## if we haven't made a \"data-derived\" directory, do so now\nif (!dir.exists(\"data-derived\")) dir.create(\"data-derived\")\n\nepdat %>%\n  filter(f_c >= -90L, f_c <= 90L) %>%\n  select(-f_id, -f_z) %>%\n  saveRDS(file = \"data-derived/edat-epoched.rds\")"
  },
  {
    "objectID": "preprocessing_2.html",
    "href": "preprocessing_2.html",
    "title": "2  Mapping gaze to areas of interest",
    "section": "",
    "text": "At this point we have epoched our eyetracking data, resulting in the edat-epoched.rds file which looks like so:\nWe know when people are looking relative to the disambiguation point for the trial (f_c), and we know where they are looking, because we have the (x, y) coordinates. But we yet don’t know which image they are looking at on each frame. So we have to map the two-dimensional gaze coordinates onto the coordinates of the images that was displayed on a given trial.\nWe know what pictures were shown on each trial from the data in the screens table (from data-raw/screens.csv).\nThe table looks like so.\nThe loc variable is a number that refers to the four quadrants of the screen where the images appeared. We can get the pixel coordinates representing the top left and bottom right corners of each rectangle from the locations table."
  },
  {
    "objectID": "preprocessing_2.html#image-locations-for-each-trial",
    "href": "preprocessing_2.html#image-locations-for-each-trial",
    "title": "2  Mapping gaze to areas of interest",
    "section": "2.1 Image locations for each trial",
    "text": "2.1 Image locations for each trial\n\n2.1.1 Activity: Get coordinates\nWe want to combine the data from screens and locations with trial info to create the following table, which we will use later to figure out what image was being looked at (if any) on each frame of each trial. Save this information in a table named aoi (for Area Of Interest). You might need to reference Appendix A to see how to get sub_id and t_id into the table.\n\n\n# A tibble: 22,576 × 8\n   sub_id  t_id  s_id role        x1    y1    x2    y2\n    <int> <int> <int> <chr>    <int> <int> <int> <int>\n 1      1     1   183 critical   704   564  1279  1023\n 2      1     1   183 existing     0   564   575  1023\n 3      1     1   183 novel        0     0   575   460\n 4      1     1   183 target     704     0  1279   460\n 5      1     2   194 critical     0   564   575  1023\n 6      1     2   194 existing   704     0  1279   460\n 7      1     2   194 novel        0     0   575   460\n 8      1     2   194 target     704   564  1279  1023\n 9      1     3    33 critical   704     0  1279   460\n10      1     3    33 existing     0   564   575  1023\n# … with 22,566 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can get sub_id and t_id from trials. But to get there from screens, we need to get the item version (iv_id) from stimuli. We can connect screens to stimuli through the screen id (s_id).\n\ntrials <- read_csv(\"data-raw/trials.csv\",\n                   col_types = \"iiiiii\")\n\nstimuli <- read_csv(\"data-raw/stimuli.csv\",\n                    col_types = \"iiciccc\")\n\naoi <- trials %>%\n  select(sub_id, t_id, iv_id) %>%\n  inner_join(stimuli, \"iv_id\") %>%\n  inner_join(screens, \"s_id\") %>%\n  inner_join(locations, \"loc\") %>%\n  select(sub_id, t_id, s_id, role, x1, y1, x2, y2)\n\nAs a check, we should have four times the number of rows as trials (5644), because there should be four areas of interest for each trial. We can use stopifnot() to make our script terminate if this condition is not satisfied.\n\nstopifnot( nrow(aoi) == 4 * nrow(trials) )"
  },
  {
    "objectID": "preprocessing_2.html#identifying-frames-where-the-gaze-cursor-is-within-an-aoi",
    "href": "preprocessing_2.html#identifying-frames-where-the-gaze-cursor-is-within-an-aoi",
    "title": "2  Mapping gaze to areas of interest",
    "section": "2.2 Identifying frames where the gaze cursor is within an AOI",
    "text": "2.2 Identifying frames where the gaze cursor is within an AOI\nWhat we need to do now is look at the (x, y) coordinates in edat and see if they fall within the bounding box for each image in the aoi table for the corresponding trial.\n\n2.2.1 Activity: Create frames_in\nThere are different ways to accomplish this task, but an effective strategy is just to join the eyedata (edat) to the aoi table and retain any frames where the x coordinate of the eye gaze is within the x1 and x2 coordinates of the rectangle, and the y coordinate is within the y1 and y2 coordinates. Because our AOIs do not overlap, the gaze can only be within a single AOI at a time.\nName the resulting table frames_in.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSome code to get you started.\n\nedat %>%\n  inner_join(aoi, c(\"sub_id\", \"t_id\")) # %>%\n  ## filter(...) \n\n\n\n\n\n\n# A tibble: 759,311 × 4\n   sub_id  t_id   f_c role  \n    <int> <int> <int> <chr> \n 1      1     1   -90 target\n 2      1     1   -89 target\n 3      1     1   -88 target\n 4      1     1   -87 target\n 5      1     1   -86 target\n 6      1     1   -85 target\n 7      1     1   -84 target\n 8      1     1   -83 target\n 9      1     1   -82 target\n10      1     1   -81 target\n# … with 759,301 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nframes_in <- edat %>%\n  inner_join(aoi, c(\"sub_id\", \"t_id\")) %>%\n  filter(x >= x1, x <= x2,\n         y >= y1, y <= y2) %>%\n  select(sub_id, t_id, f_c, role)\n\n\n\n\n\n\n2.2.2 Activity: Create frames_out\nCreate a table frames_out containing only those frames from edat where the gaze fell outside of any of the four image regions, and label those with the role (blank). Use the anti_join() function from dplyr to do so.\nThe resulting table should have the format below.\n\n\n# A tibble: 182,504 × 4\n   sub_id  t_id   f_c role   \n    <int> <int> <int> <chr>  \n 1      1     1   -69 (blank)\n 2      1     1   -68 (blank)\n 3      1     1   -66 (blank)\n 4      1     1   -49 (blank)\n 5      1     1    -9 (blank)\n 6      1     1    -8 (blank)\n 7      1     1    -7 (blank)\n 8      1     1    -6 (blank)\n 9      1     1    -5 (blank)\n10      1     1    -4 (blank)\n# … with 182,494 more rows\n\n\n\n\n\n\n\n\nHint: Show me an example of anti_join()\n\n\n\n\n\n\ntable_x <- tibble(letter = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                  number = c(1, 2, 3, 4, 5))\n\ntable_x\n\n# A tibble: 5 × 2\n  letter number\n  <chr>   <dbl>\n1 A           1\n2 B           2\n3 C           3\n4 D           4\n5 E           5\n\ntable_y <- tibble(letter = c(\"C\", \"D\", \"E\"),\n                  number = c(3, 4, 99))\n\ntable_y\n\n# A tibble: 3 × 2\n  letter number\n  <chr>   <dbl>\n1 C           3\n2 D           4\n3 E          99\n\n## which rows in table_x are not in table_y?\nanti_join(table_x, table_y, c(\"letter\", \"number\"))\n\n# A tibble: 3 × 2\n  letter number\n  <chr>   <dbl>\n1 A           1\n2 B           2\n3 E           5\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nframes_out <- edat %>% \n  select(sub_id, t_id, f_c) %>%\n  anti_join(frames_in, c(\"sub_id\", \"t_id\", \"f_c\")) %>%\n  mutate(role = \"(blank)\")\n\nA good test to do at this point is to make sure that all 941,815 rows of edat have been assigned to either frames_in or frames_out.\n\nstopifnot( nrow(edat) == (nrow(frames_in) + nrow(frames_out)) ) # TRUE\n\n\n\n\n\n\n2.2.3 Activity: Combine into pog\nCombine frames_in and frames_out into a single table by concatenating the rows. Sort the rows so by sub_id, t_id, and f_c, and convert role into type factor with levels in this order: target, critical, existing, novel, and (blank). The resulting table should be called pog and have the format below.\n\n\n# A tibble: 941,815 × 4\n   sub_id  t_id   f_c role  \n    <int> <int> <int> <fct> \n 1      1     1   -90 target\n 2      1     1   -89 target\n 3      1     1   -88 target\n 4      1     1   -87 target\n 5      1     1   -86 target\n 6      1     1   -85 target\n 7      1     1   -84 target\n 8      1     1   -83 target\n 9      1     1   -82 target\n10      1     1   -81 target\n# … with 941,805 more rows\n\n\n\n\n\n\n\n\nHow do I concatenate two tables?\n\n\n\n\n\nUse the bind_rows() function from {dplyr}.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nWe might want to check that role has been defined properly.\n\npog %>%\n  pull(role) %>%\n  levels()\n\n[1] \"target\"   \"critical\" \"existing\" \"novel\"    \"(blank)\""
  },
  {
    "objectID": "preprocessing_2.html#dealing-with-trial-dropouts",
    "href": "preprocessing_2.html#dealing-with-trial-dropouts",
    "title": "2  Mapping gaze to areas of interest",
    "section": "2.3 Dealing with trial dropouts",
    "text": "2.3 Dealing with trial dropouts\n\n\n\nWe want to be able to use the data in pog to calculate probabilities of gazing at regions over time. However, we are not ready to do this yet.\nIf we look at the first seven trials from subject 3, we can see that there is a problem, because the trials end at different times, due to variation in response time. If we plot the resulting data, we will have fewer and fewer data points as we progress through the trial.\n\n\n\n\n\nA solution to this is to make each time series “cumulative to selection”, which means padding frames after the trial ends with artificial looks to the object that was selected. In other words, we pretend that the subject remained fixated on the selected object after clicking.\nBut before we do this, we should double check that trials also start at the same frame (-90). Once we pass this sanity check we can pad frames at the end.\n\nstart_frame <- edat %>% \n  group_by(sub_id, t_id) %>% \n  summarise(min_f_c = min(f_c), # get the minimum frame per trial\n            .groups = \"drop\") %>%\n  pull(min_f_c) %>%\n  unique() # what are the unique values?\n\n## if the value is the same for every trial, there should be\n## just one element in this vector\nstopifnot( length(start_frame) == 1L )\n\nstart_frame\n\n[1] -90\n\n\n\n2.3.1 Activity: Selected object\nWhich object was selected on each trial? The trials table tells us which location was clicked (1, 2, 3, 4) but not which object. We need to figure out which object was clicked by retrieving that information from the screens table. The result should have the format below.\n\n\n# A tibble: 5,644 × 3\n   sub_id  t_id role  \n    <int> <int> <chr> \n 1      1     1 target\n 2      1     2 target\n 3      1     3 target\n 4      1     4 target\n 5      1     6 target\n 6      1     7 target\n 7      1    11 target\n 8      1    13 target\n 9      1    14 target\n10      1    16 target\n# … with 5,634 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## which object was selected on each trial?\nselections <- trials %>%\n  inner_join(stimuli, \"iv_id\") %>%\n  inner_join(screens, c(\"s_id\", \"resploc\" = \"loc\")) %>%\n  select(sub_id, t_id, role)\n\n\n\n\nNow that we know what object was selected, we want to pad trials up to the latest frame in the dataset, which we determined during epoching as frame 90 (that is, 1.5 seconds after the disambiguation point).\nWe will use the crossing() function (from {tidyr}) to create a table with all combinations of the rows from selections with frames f_c from 0 to 90. Then, in the next activity, we will use anti_join() to pull out the combinations that are missing from pog, and use them in padding.\n\nall_frames <- crossing(selections, tibble(f_c = 0:90))\n\nall_frames\n\n# A tibble: 513,604 × 4\n   sub_id  t_id role     f_c\n    <int> <int> <chr>  <int>\n 1      1     1 target     0\n 2      1     1 target     1\n 3      1     1 target     2\n 4      1     1 target     3\n 5      1     1 target     4\n 6      1     1 target     5\n 7      1     1 target     6\n 8      1     1 target     7\n 9      1     1 target     8\n10      1     1 target     9\n# … with 513,594 more rows\n\n\n\n\n2.3.2 Activity: Pad frames\nUse anti_join() to find out which frames in all_frames are missing from pog. Concatenate these frames onto pog, storing the result in pog_cts. The resulting table should have a variable pad which is FALSE if the frame is an original one, and TRUE if it was added through the padding procedure. Sort the rows of pog_cts by sub_id, t_id, and f_c. The format is shown below.\n\n\n# A tibble: 1,021,288 × 5\n   sub_id  t_id   f_c role   pad  \n    <int> <int> <int> <chr>  <lgl>\n 1      1     1   -90 target FALSE\n 2      1     1   -89 target FALSE\n 3      1     1   -88 target FALSE\n 4      1     1   -87 target FALSE\n 5      1     1   -86 target FALSE\n 6      1     1   -85 target FALSE\n 7      1     1   -84 target FALSE\n 8      1     1   -83 target FALSE\n 9      1     1   -82 target FALSE\n10      1     1   -81 target FALSE\n# … with 1,021,278 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\nOne thing that may have happened in the process above is that role is no longer a factor. So let’s convert it back before we finish.\n\npog_cts2 <- pog_cts %>%\n  mutate(role = fct_relevel(role, c(\"target\", \"critical\",\n                                    \"existing\", \"novel\", \"(blank)\")))\n\nNow let’s double check that the padding worked by looking again at some trials from subject 3.\n\n\n\n\n\nLooks good. Now let’s save all our hard work so that we can use pog_cts2 as a starting point for analysis.\n\nsaveRDS(pog_cts2, \"data-derived/pog_cts.rds\")"
  },
  {
    "objectID": "plotting.html",
    "href": "plotting.html",
    "title": "3  Plot probabilities",
    "section": "",
    "text": "In the last chapter, we completed data preprocessing and saved the resulting data to as an R binary RDS file, pog_cts.rds. In this chapter, we will import the data and use it to recreate some of the figures in Weighall et al. (2017).\nFirst, let’s load in {tidyverse} and then import the point-of-gaze data.\nAs usual, the first thing we should do is have a look at our data.\nThe data has sub_id and t_id which identify individual subjects and trials-within-subjects, respectively. But we are missing iformation about what group the subject belongs to (adult or child) and what experimental condition each trial belongs to."
  },
  {
    "objectID": "plotting.html#merge-eye-data-with-information-about-group-and-condition",
    "href": "plotting.html#merge-eye-data-with-information-about-group-and-condition",
    "title": "3  Plot probabilities",
    "section": "3.1 Merge eye data with information about group and condition",
    "text": "3.1 Merge eye data with information about group and condition\n\n3.1.1 Activity: Get trial condition\nThe first step is to create trial_cond, which has information about the group that each subject belongs to, the competitor type (existing or novel), and the condition (the identity of the critical object). The information we need is distributed across the subjects, trials, and stimuli tables (see Appendix A). Create trial_cond so that the resulting table matches the format below.\n\n\n# A tibble: 5,644 × 5\n   sub_id group  t_id ctype crit           \n    <int> <chr> <int> <chr> <chr>          \n 1      1 adult     1 novel competitor-day2\n 2      1 adult     2 novel competitor-day1\n 3      1 adult     3 exist competitor     \n 4      1 adult     4 exist competitor     \n 5      1 adult     6 novel untrained      \n 6      1 adult     7 novel competitor-day1\n 7      1 adult    11 novel untrained      \n 8      1 adult    13 novel competitor-day2\n 9      1 adult    14 novel untrained      \n10      1 adult    16 novel untrained      \n# … with 5,634 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ntrials <- read_csv(\"data-raw/trials.csv\",\n                   col_types = \"iiiiii\")\n\nstimuli <- read_csv(\"data-raw/stimuli.csv\",\n                    col_types = \"iiciccc\")\n\nsubjects <- read_csv(\"data-raw/subjects.csv\",\n                     col_types = \"ic\")\n\ntrial_cond <- trials %>%\n  inner_join(stimuli, \"iv_id\") %>%\n  inner_join(subjects, \"sub_id\") %>%\n  select(sub_id, group, t_id, ctype, crit)"
  },
  {
    "objectID": "plotting.html#plot-probabilities-for-existing-competitors",
    "href": "plotting.html#plot-probabilities-for-existing-competitors",
    "title": "3  Plot probabilities",
    "section": "3.2 Plot probabilities for existing competitors",
    "text": "3.2 Plot probabilities for existing competitors\nWe want to determine the probability of looking at each image type at each frame in each condition. We will do this first for the existing competitors. Note there were two conditions here, indexed by crit: competitor and unrelated, corresponding to whether the critical image was a competitor or an unrelated item.\n\n3.2.1 Activity: Probs for exist condition\nFrom trial_cond, include only those trials where ctype takes on the value exist, combine with pog_cts, and then count the number of frames in each region for every combination of the levels of group (adult, child) and crit (competitor, unrelated). The resulting table should have the format below, where Y is the number of frames for each combination. While you’re at it, convert f_c to milliseconds (1000 * f_c / 60). Call the resulting table count_exist.\n\n\n\n\n\n\nHint: Counting things\n\n\n\n\n\nUse the count() function from {dplyr}. Take note of the .drop argument to deal with possible situations where there are zero observations. For example:\n\npets <- tibble(animal = factor(rep(c(\"dog\", \"cat\", \"ferret\"), c(3, 2, 0)),\n                               levels = c(\"dog\", \"cat\", \"ferret\")))\n\npets\n\n# A tibble: 5 × 1\n  animal\n  <fct> \n1 dog   \n2 dog   \n3 dog   \n4 cat   \n5 cat   \n\npets %>%\n  count(animal)\n\n# A tibble: 2 × 2\n  animal     n\n  <fct>  <int>\n1 dog        3\n2 cat        2\n\npets %>%\n  count(animal, .drop = FALSE)\n\n# A tibble: 3 × 2\n  animal     n\n  <fct>  <int>\n1 dog        3\n2 cat        2\n3 ferret     0\n\n\n\n\n\n\n\n# A tibble: 3,620 × 6\n   group crit         f_c role         Y     ms\n   <chr> <chr>      <int> <fct>    <int>  <dbl>\n 1 adult competitor   -90 target      54 -1500 \n 2 adult competitor   -90 critical    55 -1500 \n 3 adult competitor   -90 existing    55 -1500 \n 4 adult competitor   -90 novel       75 -1500 \n 5 adult competitor   -90 (blank)    181 -1500 \n 6 adult competitor   -89 target      59 -1483.\n 7 adult competitor   -89 critical    60 -1483.\n 8 adult competitor   -89 existing    58 -1483.\n 9 adult competitor   -89 novel       74 -1483.\n10 adult competitor   -89 (blank)    169 -1483.\n# … with 3,610 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncount_exist <- trial_cond %>%\n  filter(ctype == \"exist\") %>%\n  inner_join(pog_cts, c(\"sub_id\", \"t_id\")) %>%\n  count(group, crit, f_c, role, name = \"Y\", .drop = FALSE) %>%\n  mutate(ms = 1000 * f_c / 60)\n\n\n\n\nTo calculate the probability for each value of role, we need to calculate the number of opportunities for each combination of group, crit, and f_c, storing this in N. We do this using a windowed mutate, grouping the data before adding N for each group. We can then calculate the probability as p = Y / N.\n\nprob_exist <- count_exist %>%\n  group_by(group, crit, f_c) %>%\n  mutate(N = sum(Y), p = Y / N) %>%\n  ungroup()\n\nNow we are ready to plot.\n\nggplot(prob_exist %>% filter(role != \"(blank)\"), \n       aes(ms, p, color = role)) +\n  geom_line() +\n  facet_wrap(group ~ crit, nrow = 2)  +\n  coord_cartesian(xlim = c(-200, 1000))\n\n\n\n\n\n\n\n\nWeighall, AR, Lisa-Marie Henderson, DJ Barr, Scott Ashley Cairney, and Mark Gareth Gaskell. 2017. “Eye-Tracking the Time-Course of Novel Word Learning and Lexical Competition in Adults and Children.” Brain and Language 167: 13–27."
  },
  {
    "objectID": "polynomial.html",
    "href": "polynomial.html",
    "title": "4  Polynomial regression",
    "section": "",
    "text": "For more information about these approaches, see Barr (2008) and Mirman, Dixon, and Magnuson (2008). It is also possible to use Generalized Additive Mixed Models (GAMMs), which can more easily accommodate arbitrary wiggly patterns and asymptotes, but that is beyond the current scope of this textbook."
  },
  {
    "objectID": "polynomial.html#binning-data",
    "href": "polynomial.html#binning-data",
    "title": "4  Polynomial regression",
    "section": "4.1 Binning data",
    "text": "4.1 Binning data\nWe are going to follow the Mirman, Dixon, and Magnuson (2008) approach. What we want to do first is to model the shape of the curve for existing competitors and see if it differs across children and adults.\nWe will perform separate by-subject and by-item analysis. The reason why this is needed is that we have to first aggregate the data in order to deal with the frame-by-frame dependencies. A common approach is to aggregate frames into 50 ms bins (i.e. each having 3 frames).\nThe general formula for binning data is:\nbin = floor( (frame + binsize/2) / binsize ) * binsize\nTo bin things up into bins of 3 frames each, it would be\nbin = floor( (frame + 3/2) / 3) * 3\nTo get a sense for how this formula works, try it out in the console.\n\nsample_frames <- -10:10\n\nrbind(frame = sample_frames,\n      bin = floor( (sample_frames + 3/2) / 3) * 3)\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\nframe  -10   -9   -8   -7   -6   -5   -4   -3   -2    -1     0     1     2\nbin     -9   -9   -9   -6   -6   -6   -3   -3   -3     0     0     0     3\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]\nframe     3     4     5     6     7     8     9    10\nbin       3     3     6     6     6     9     9     9\n\n\n\n\n\n\n\n\nWhy add half a bin?\n\n\n\nShifting frames forward by half of the binsize gives us more accurate bin numbering. To see why, consider the unshifted version to our shifted version above.\n\n## unshifted version\nrbind(frame = sample_frames,\n      bin = floor(sample_frames / 3) * 3)\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\nframe  -10   -9   -8   -7   -6   -5   -4   -3   -2    -1     0     1     2\nbin    -12   -9   -9   -9   -6   -6   -6   -3   -3    -3     0     0     0\n      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]\nframe     3     4     5     6     7     8     9    10\nbin       3     3     3     6     6     6     9     9\n\n\nNote that in the shifted version, the bin name corresponds to the median frame contained in the bin, whereas in the unshifted version, it corresponds to the first frame in the bin. For instance, bin 0, contains -1, 0, and 1 in the shifted version; in the unshifted version, it contains 0, 1, and 2.\n\n\n\n4.1.1 Activity: Calculating bins\nFollowing the above logic, add the variables bin and ms (time in milliseconds for the corresponding bin) to the pog table. Save the result as pog_calc.\n\n\n# A tibble: 1,021,288 × 7\n   sub_id  t_id   f_c role   pad     bin    ms\n    <int> <int> <int> <fct>  <lgl> <int> <int>\n 1      1     1   -90 target FALSE   -30  -500\n 2      1     1   -89 target FALSE   -30  -500\n 3      1     1   -88 target FALSE   -29  -483\n 4      1     1   -87 target FALSE   -29  -483\n 5      1     1   -86 target FALSE   -29  -483\n 6      1     1   -85 target FALSE   -28  -466\n 7      1     1   -84 target FALSE   -28  -466\n 8      1     1   -83 target FALSE   -28  -466\n 9      1     1   -82 target FALSE   -27  -450\n10      1     1   -81 target FALSE   -27  -450\n# … with 1,021,278 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npog_calc <- pog %>%\n  mutate(bin = floor((f_c + 3/2) / 3) %>% as.integer(),\n         ms = as.integer(1000 * bin / 60))\n\n\n\n\n\n\n4.1.2 Activity: Count frames in bins\nFor the analysis below, we’re going to focus on the existing competitors (ctype == \"exist\"). Link the pog_calc data to information about subjects and conditions (crit) to create the following table, where Y is the number of frames observed for the particular combination of sub_id, group, crit, ms, and role. Save the resulting table as pog_subj_y.\n\n\n# A tibble: 50,630 × 6\n   sub_id group crit          ms role         Y\n    <int> <chr> <chr>      <int> <fct>    <int>\n 1      1 adult competitor  -500 target       6\n 2      1 adult competitor  -500 critical     4\n 3      1 adult competitor  -500 existing     4\n 4      1 adult competitor  -500 novel        6\n 5      1 adult competitor  -500 (blank)      0\n 6      1 adult competitor  -483 target       7\n 7      1 adult competitor  -483 critical     5\n 8      1 adult competitor  -483 existing     8\n 9      1 adult competitor  -483 novel        8\n10      1 adult competitor  -483 (blank)      2\n# … with 50,620 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsubjects <- read_csv(\"data-raw/subjects.csv\",\n                     col_types = \"ic\")\n\ntrials <- read_csv(\"data-raw/trials.csv\",\n                   col_types = \"iiiiii\")\n\nstimuli <- read_csv(\"data-raw/stimuli.csv\",\n                    col_types = \"iiciccc\")\n\npog_subj_y <- pog_calc %>%\n  inner_join(subjects, \"sub_id\") %>%\n  inner_join(trials, c(\"sub_id\", \"t_id\")) %>%\n  inner_join(stimuli, c(\"iv_id\")) %>%\n  filter(ctype == \"exist\") %>%\n  count(sub_id, group, crit, ms, role,\n        name = \"Y\", .drop = FALSE)\n\n\n\n\n\n\n4.1.3 Activity: Compute probabilities\nNow add in variables N, the total number of frames for a given combination of sub_id, group, crit, and ms, and p, which is the probability (Y / N). Save the result as pog_subj.\n\n\n# A tibble: 50,630 × 8\n   sub_id group crit          ms role         Y     N      p\n    <int> <chr> <chr>      <int> <fct>    <int> <int>  <dbl>\n 1      1 adult competitor  -500 target       6    20 0.3   \n 2      1 adult competitor  -500 critical     4    20 0.2   \n 3      1 adult competitor  -500 existing     4    20 0.2   \n 4      1 adult competitor  -500 novel        6    20 0.3   \n 5      1 adult competitor  -500 (blank)      0    20 0     \n 6      1 adult competitor  -483 target       7    30 0.233 \n 7      1 adult competitor  -483 critical     5    30 0.167 \n 8      1 adult competitor  -483 existing     8    30 0.267 \n 9      1 adult competitor  -483 novel        8    30 0.267 \n10      1 adult competitor  -483 (blank)      2    30 0.0667\n# … with 50,620 more rows\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall what we did back in the plotting chapter, when creating probs_exist (a windowed mutate). You’ll need to do something like that again here.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npog_subj <- pog_subj_y %>%\n  group_by(sub_id, group, crit, ms) %>%\n  mutate(N = sum(Y),\n         p = Y / N) %>%\n  ungroup()"
  },
  {
    "objectID": "polynomial.html#plot-mean-probabilities",
    "href": "polynomial.html#plot-mean-probabilities",
    "title": "4  Polynomial regression",
    "section": "4.2 Plot mean probabilities",
    "text": "4.2 Plot mean probabilities\n\n4.2.1 Activity: Mean probabilities\nLet’s now compute the mean probabilities for looks to the critical object across groups (adults, children) and condition (competitor, unrelated). First calculate the table pog_means below, then use it to create the graph below.\n\n\n# A tibble: 244 × 4\n   group crit          ms probability\n   <chr> <chr>      <int>       <dbl>\n 1 adult competitor  -500       0.137\n 2 adult competitor  -483       0.140\n 3 adult competitor  -466       0.131\n 4 adult competitor  -450       0.129\n 5 adult competitor  -433       0.135\n 6 adult competitor  -416       0.137\n 7 adult competitor  -400       0.135\n 8 adult competitor  -383       0.138\n 9 adult competitor  -366       0.137\n10 adult competitor  -350       0.129\n# … with 234 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npog_means <- pog_subj %>%\n  filter(role == \"critical\") %>%\n  group_by(group, crit, ms) %>%\n  summarize(probability = mean(p),\n            .groups = \"drop\")\n\n\nggplot(pog_means, aes(ms, probability,\n                      shape = crit, color = group)) +\n  geom_point(alpha = .5) +\n  coord_cartesian(xlim = c(-200, 500)) +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "polynomial.html#polynomial-regression",
    "href": "polynomial.html#polynomial-regression",
    "title": "4  Polynomial regression",
    "section": "4.3 Polynomial regression",
    "text": "4.3 Polynomial regression\nOur task now is to fit the functions shown in the above figure using orthogonal polynomials. To avoid asymptotes, we will limit our analysis to 200 to 500 ms window, which is where the function seems to be changing.\nThe first thing we will do is prepare the data, adding in deviation-coded numerical predictors for group (G) and crit (C).\nWe will load in the R packages {lme4} for fitting linear mixed-effects models, and {polypoly} for working with orthogonal polynomials.\n\n# if you don't have it, type\n# install.packages(\"polypoly\") # in the console\nlibrary(\"polypoly\")\nlibrary(\"lme4\")\n\npog_prep <- pog_subj %>%\n  filter(role == \"critical\", ms >= -200) %>%\n  mutate(G = if_else(group == \"child\", 1/2, -1/2),\n         C = if_else(crit == \"competitor\", 1/2, -1/2))\n\n## check that we didn't make any errors\npog_prep %>%\n  distinct(group, crit, G, C)\n\n# A tibble: 4 × 4\n  group crit           G     C\n  <chr> <chr>      <dbl> <dbl>\n1 adult competitor  -0.5   0.5\n2 adult unrelated   -0.5  -0.5\n3 child competitor   0.5   0.5\n4 child unrelated    0.5  -0.5\n\n\n\npog_3 <- pog_prep %>%\n  poly_add_columns(ms, degree = 3) %>%\n  select(sub_id, group, G, crit, C, ms, p, ms1, ms2, ms3)\n\n\nmod_3 <- lmer(p ~ (ms1 + ms2 + ms3) * G * C +\n                ((ms1 + ms2 + ms3) * C || sub_id), \n              data = pog_3)\n\nsummary(mod_3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: p ~ (ms1 + ms2 + ms3) * G * C + ((1 | sub_id) + (0 + ms1 | sub_id) +  \n    (0 + ms2 | sub_id) + (0 + ms3 | sub_id) + (0 + C | sub_id) +  \n    (0 + ms1:C | sub_id) + (0 + ms2:C | sub_id) + (0 + ms3:C |      sub_id))\n   Data: pog_3\n\nREML criterion at convergence: -14758.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2565 -0.5914 -0.0358  0.5113  5.4038 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n sub_id   (Intercept) 0.001249 0.03534 \n sub_id.1 ms1         0.054835 0.23417 \n sub_id.2 ms2         0.027294 0.16521 \n sub_id.3 ms3         0.026226 0.16194 \n sub_id.4 C           0.003698 0.06081 \n sub_id.5 ms1:C       0.128879 0.35900 \n sub_id.6 ms2:C       0.106783 0.32678 \n sub_id.7 ms3:C       0.061623 0.24824 \n Residual             0.005815 0.07625 \nNumber of obs: 7138, groups:  sub_id, 83\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept)  0.133722   0.003983  33.569\nms1         -0.360730   0.026378 -13.676\nms2         -0.188137   0.019077  -9.862\nms3          0.134597   0.018736   7.184\nG            0.027162   0.007967   3.409\nC            0.030741   0.006915   4.445\nms1:G        0.108453   0.052756   2.056\nms2:G       -0.035381   0.038154  -0.927\nms3:G       -0.088315   0.037473  -2.357\nms1:C        0.058203   0.041147   1.414\nms2:C       -0.193833   0.037774  -5.131\nms3:C        0.045101   0.029710   1.518\nG:C          0.001996   0.013831   0.144\nms1:G:C      0.068046   0.082295   0.827\nms2:G:C      0.082218   0.075548   1.088\nms3:G:C     -0.127579   0.059420  -2.147\n\n\n\nCorrelation matrix not shown by default, as p = 16 > 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\nIt converged! Before we get too excited, plot the model fitted values against the observed values to assess the quality of the fit.\nWe need data to feed in to the predict() function in order to generate our fitted values. We’ll use pog_means for this purpose, adding in all of the predictors we need for the model, and restricting the range.\n\npog_new <- pog_means %>%\n  filter(ms >= -200) %>%\n  mutate(G = if_else(group == \"child\", 1/2, -1/2),\n         C = if_else(crit == \"competitor\", 1/2, -1/2)) \n\nNow we are ready to feed it into predict() to generate fitted values. Note that we want to make predictions for the “typical” subject with random effects of zero, which requires setting re.form = NA for the predict() function. See ?predict.merMod for details. We use newdata = . to send the current data from our pipeline as the argument for newdata.\n\nfits_3 <- pog_new %>%\n  poly_add_columns(ms, degree = 3) %>%\n  mutate(fitted = predict(mod_3, newdata = .,\n                          re.form = NA))\n\nNow we plot the fitted values (lines) against observed (points).\n\nggplot(fits_3,\n       aes(ms, probability,\n           shape = crit, color = group)) +\n  geom_point() +\n  geom_line(aes(y = fitted, linetype = crit)) +\n  theme(legend.position = \"top\")\n\n\n\n\nNot good. We might want to try a higher order model. Alternatively, we can restrict the range further to get rid of asymptotic elements in the later part of the window. Let’s try the latter first because that’s fairly easy.\n\npog_3b <- pog_3 %>%\n  filter(between(ms, -50L, 300L))\n\n## refit with a different dataset\nmod_3b <- update(mod_3, data = pog_3b)\n\nGenerate fitted values from the new model and plot.\n\nfits_3b <- pog_new %>%\n  filter(between(ms, -50L, 300L)) %>%\n  poly_add_columns(ms, degree = 3) %>%\n  mutate(fitted = predict(mod_3b, newdata = .,\n                          re.form = NA))\n\nggplot(fits_3b,\n       aes(ms, probability,\n           shape = crit, color = group)) +\n  geom_point() +\n  geom_line(aes(y = fitted, linetype = crit)) +\n  theme(legend.position = \"top\")\n\n\n\n\nWell, that is even worse.\n\n4.3.1 Activity: Quintic model\nA cubic is really not enough. Try to fit a quintic (5th order) function on the reduced data range (-50 ms to 300 ms). Use the bobyqa optimizer to get lmer() to converge (control = lmerControl(optimizer = \"bobyqa\")), and fit it with REML=FALSE.\nThen, follow the example above to assess the quality of fit using a plot.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npog_5 <- pog_prep %>%\n  filter(between(ms, -50L, 300L)) %>%\n  poly_add_columns(ms, degree = 5)\n\nmod_5 <- lmer(p ~ (ms1 + ms2 + ms3 + ms4 + ms5) * G * C +\n                ((ms1 + ms2 + ms3 + ms4 + ms5) * C || sub_id), \n              data = pog_5, REML=FALSE,\n              control = lmerControl(optimizer = \"bobyqa\"))\n\nNow evaluate the fit.\n\nfits_5 <- pog_new %>%\n  filter(between(ms, -50L, 300L)) %>%\n  poly_add_columns(ms, degree = 5) %>%\n  mutate(fitted = predict(mod_5, newdata = .,\n                          re.form = NA))\n\nggplot(fits_5,\n       aes(ms, probability,\n           shape = crit, color = group)) +\n  geom_point() +\n  geom_line(aes(y = fitted, linetype = crit)) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nOK, that’s a fit that we can be happy with.\nLet’s have a look at the model output.\n\nsummary(mod_5)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: p ~ (ms1 + ms2 + ms3 + ms4 + ms5) * G * C + ((1 | sub_id) + (0 +  \n    ms1 | sub_id) + (0 + ms2 | sub_id) + (0 + ms3 | sub_id) +  \n    (0 + ms4 | sub_id) + (0 + ms5 | sub_id) + (0 + C | sub_id) +  \n    (0 + ms1:C | sub_id) + (0 + ms2:C | sub_id) + (0 + ms3:C |  \n    sub_id) + (0 + ms4:C | sub_id) + (0 + ms5:C | sub_id))\n   Data: pog_5\nControl: lmerControl(optimizer = \"bobyqa\")\n\n     AIC      BIC   logLik deviance df.resid \n -9233.6  -9004.1   4653.8  -9307.6     3615 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2631 -0.4883 -0.0013  0.4694  4.4521 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n sub_id    (Intercept) 0.002499 0.04999 \n sub_id.1  ms1         0.046758 0.21624 \n sub_id.2  ms2         0.017703 0.13305 \n sub_id.3  ms3         0.014331 0.11971 \n sub_id.4  ms4         0.005942 0.07709 \n sub_id.5  ms5         0.006101 0.07811 \n sub_id.6  C           0.007937 0.08909 \n sub_id.7  ms1:C       0.113327 0.33664 \n sub_id.8  ms2:C       0.075215 0.27425 \n sub_id.9  ms3:C       0.061012 0.24701 \n sub_id.10 ms4:C       0.020677 0.14380 \n sub_id.11 ms5:C       0.021688 0.14727 \n Residual              0.002148 0.04635 \nNumber of obs: 3652, groups:  sub_id, 83\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept)  0.167871   0.005541  30.295\nms1         -0.209290   0.024008  -8.718\nms2         -0.121173   0.015042  -8.056\nms3          0.006115   0.013625   0.449\nms4          0.046584   0.009195   5.066\nms5          0.003498   0.009299   0.376\nG            0.026723   0.011082   2.411\nC            0.054710   0.009899   5.527\nms1:G        0.148235   0.048016   3.087\nms2:G        0.006309   0.030084   0.210\nms3:G       -0.070349   0.027249  -2.582\nms4:G        0.018576   0.018390   1.010\nms5:G        0.006853   0.018597   0.368\nms1:C        0.010683   0.037648   0.284\nms2:C       -0.191025   0.030953  -6.171\nms3:C        0.006511   0.028053   0.232\nms4:C        0.099358   0.017347   5.728\nms5:C       -0.003818   0.017695  -0.216\nG:C         -0.009915   0.019798  -0.501\nms1:G:C      0.144761   0.075295   1.923\nms2:G:C      0.046990   0.061907   0.759\nms3:G:C     -0.156586   0.056106  -2.791\nms4:G:C      0.009317   0.034695   0.269\nms5:G:C      0.061278   0.035390   1.732\n\n\n\nCorrelation matrix not shown by default, as p = 24 > 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\nNow let’s use model comparison to answer our question: do the time-varying components for lexical competition vary across children and adults?\n\nmod_5_drop <- \n  update(mod_5,\n         . ~ . -ms1:G:C -ms2:G:C -ms3:G:C -ms4:G:C -ms5:G:C)\n\nanova(mod_5, mod_5_drop)\n\nData: pog_5\nModels:\nmod_5_drop: p ~ ms1 + ms2 + ms3 + ms4 + ms5 + G + C + (1 | sub_id) + (0 + ms1 | sub_id) + (0 + ms2 | sub_id) + (0 + ms3 | sub_id) + (0 + ms4 | sub_id) + (0 + ms5 | sub_id) + (0 + C | sub_id) + (0 + ms1:C | sub_id) + (0 + ms2:C | sub_id) + (0 + ms3:C | sub_id) + (0 + ms4:C | sub_id) + (0 + ms5:C | sub_id) + ms1:G + ms2:G + ms3:G + ms4:G + ms5:G + ms1:C + ms2:C + ms3:C + ms4:C + ms5:C + G:C\nmod_5: p ~ (ms1 + ms2 + ms3 + ms4 + ms5) * G * C + ((1 | sub_id) + (0 + ms1 | sub_id) + (0 + ms2 | sub_id) + (0 + ms3 | sub_id) + (0 + ms4 | sub_id) + (0 + ms5 | sub_id) + (0 + C | sub_id) + (0 + ms1:C | sub_id) + (0 + ms2:C | sub_id) + (0 + ms3:C | sub_id) + (0 + ms4:C | sub_id) + (0 + ms5:C | sub_id))\n           npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)  \nmod_5_drop   32 -9229.0 -9030.5 4646.5  -9293.0                       \nmod_5        37 -9233.6 -9004.1 4653.8  -9307.6 14.653  5    0.01195 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere are further things we could potentially do with this model, including performing model comparison on the time-varying components. One thing we probably should do would be to repeat all the above steps, but treating items as a random factor instead of subjects.\nOne issue with polynomial regression is that the complexity of the model is likely to give rise to convergence problems. One strategy is to estimate the parameters using re-sampling techniques, which we’ll learn about in the next chapter.\nBefore we do that, let’s save pog_subj, because we’ll need it for the next set of activities.\n\npog_subj %>%\n  saveRDS(file = \"data-derived/pog_subj.rds\")\n\n\n\n\n\nBarr, Dale J. 2008. “Analyzing ‘Visual World’ Eyetracking Data Using Multilevel Logistic Regression.” Journal of Memory and Language 59: 457–74.\n\n\nMirman, Daniel, James A Dixon, and James S Magnuson. 2008. “Statistical and computational models of the visual world paradigm: Growth curves and individual differences.” Journal of Memory and Language 59 (4): 475–94."
  },
  {
    "objectID": "clust-perm.html",
    "href": "clust-perm.html",
    "title": "5  Cluster-permutation analysis",
    "section": "",
    "text": "Cluster-permutation analysis was first developed for statistical problems in fMRI (Bullmore et al. 1999) and EEG/MEG research (Maris and Oostenveld 2007). It developed as a means of controlling the false positive rates for numerous tests across electrode, voxel, and time, without incurring the catastrophic hit to power that would occur using conventional (Bonferroni-type) correction methods. Usually you would use this approach when you more are interested in when an effect arises than in the overall shape of effects across an analysis window. However, I would be remiss not to mention a recent article which takes a critical view on its ability to establish the locus of effects in time (Sassenhagen and Draschkow 2019). But it is still useful for establishing a time range around which ‘something is happening’ even if it doesn’t allow us to express uncertainty around the boundaries of that time range (which would be even more useful)."
  },
  {
    "objectID": "clust-perm.html#our-task",
    "href": "clust-perm.html#our-task",
    "title": "5  Cluster-permutation analysis",
    "section": "5.1 Our task",
    "text": "5.1 Our task\nWhat we are going to do is run a cluster-permutation analysis on the data below, to see when the group-by-competition interaction is likely to be reliable.\n\nFor the analysis, we’ll need two development packages (only available on github): {exchangr} and {clusterperm}. The former does exchangeable permutations, and the latter more specifically for this kind of analysis.\nWe’re going to use the data pog_subj that we created in the last chapter and saved in the data-derived/ subdirectory. We’re going to be performing ANOVAs on the data using aov(), so we’ll need to define our independent variables as factors.\n\nlibrary(\"tidyverse\")\nlibrary(\"exchangr\") # remotes::install_github(\"dalejbarr/exchangr\")\nlibrary(\"clusterperm\") # remotes::install_github(\"dalejbarr/clustperm\")\n\npog_subj <- read_rds(\"data-derived/pog_subj.rds\") %>%\n  filter(role == \"critical\",\n         between(ms, -200, 300)) %>%\n  select(-role, -Y, -N) %>%\n  mutate(group = factor(group),\n         crit = factor(crit),\n         sub_id = factor(sub_id))\n\n\n\n\nLet’s take a moment to understand the aov() function from base R. Imagine that instead of having multiple frames, we wanted to run an ANOVA on a single time point, say at 150 ms. We have a mixed design (group = between-subjects; crit = within-subjects), so the way we would do it is as shown below.\n\npog_150 <- pog_subj %>%\n  filter(ms == 150L) %>%\n  select(-ms)\n\nmod_aov <- aov(p ~ group * crit + Error(sub_id / crit),\n               pog_150)\n\nsummary(mod_aov)\n\n\nError: sub_id\n          Df Sum Sq Mean Sq F value  Pr(>F)   \ngroup      1 0.1067 0.10669   7.584 0.00727 **\nResiduals 81 1.1395 0.01407                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: sub_id:crit\n           Df Sum Sq Mean Sq F value   Pr(>F)    \ncrit        1 0.5552  0.5552  27.098 1.43e-06 ***\ngroup:crit  1 0.0075  0.0075   0.366    0.547    \nResiduals  81 1.6595  0.0205                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n5.1.1 Activity: aov_by_bin()\nThe aov_by_bin() function from {clusterperm} will run that same ANOVA at every bin in the dataset. Try it, plugging in the same formula from above. Save the result as orig_result.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\norig_result <- aov_by_bin(pog_subj, ms,\n                          p ~ group * crit + Error(sub_id / crit))\n\norig_result\n\n# A tibble: 93 × 4\n      ms effect        stat      p\n   <int> <chr>        <dbl>  <dbl>\n 1  -200 group       0.0329 0.857 \n 2  -200 crit       -3.44   0.0672\n 3  -200 group:crit -2.66   0.107 \n 4  -183 group       0.0456 0.831 \n 5  -183 crit       -2.18   0.143 \n 6  -183 group:crit -0.654  0.421 \n 7  -166 group      -0.189  0.665 \n 8  -166 crit       -1.11   0.295 \n 9  -166 group:crit -0.219  0.641 \n10  -150 group      -0.535  0.467 \n# … with 83 more rows\n\n\n\n\n\nThe function aov_by_bin() returns the variable stat, which is a signed F statistic, and is positive or negative depending on the direction of the effect. It also returns p, which is the p-value for the effect at the corresponding bin.\nA ‘cluster’ is defined as a set of temporally-adjacent bins where all of the test statistics have the same signs, and the p-values are all less than alpha (where alpha is the false positive level, usually .05). We look for these temporally adjacent bins for each main effect or interaction.\nIn this case we have two main effects (group and crit) and one interaction (group:crit), and we can detect clusters for each one of these.\n\n\n5.1.2 Activity: Detect clusters\nThe {clusterperm} package provides a function to do this, detect_clusters_by_effect(), which is fed the output of aov_by_bin(). Try applying this function to orig_result, and save the result as clusters.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nclusters <- orig_result %>%\n  detect_clusters_by_effect(effect, ms, stat, p)\n\nclusters\n\n# A tibble: 3 × 5\n  effect        b0    b1  sign   cms\n  <chr>      <int> <int> <dbl> <dbl>\n1 group        150   300    -1 169. \n2 crit          33   216     1 284. \n3 group:crit    33    66     1  21.5\n\n\nb0 and b1 tell you the start and end frames for each cluster; sign gives you the direction of the effect, and cms gives you the “cluster mass statistic”, which is the summed test statistics for the entire cluster."
  },
  {
    "objectID": "clust-perm.html#deriving-null-hypothesis-distributions-through-resampling",
    "href": "clust-perm.html#deriving-null-hypothesis-distributions-through-resampling",
    "title": "5  Cluster-permutation analysis",
    "section": "5.2 Deriving null-hypothesis distributions through resampling",
    "text": "5.2 Deriving null-hypothesis distributions through resampling\nA permutation test has proceeds according to the following steps:\n\nperform an analysis on the original data and store the resulting test statistic;\ngenerate a null-hypothesis distribution for the test statistic by randomly permuting labels, re-running the analysis, and storing the test statistic many times;\ncompare the original test statistic to the distribution of statistics you generated in step 2 to determine how unlikely your original test statistic is under the null hypothesis.\n\n\n\n\n\n\n\nWarning\n\n\n\nThe logic of permutation tests is appealing, but you can really get into trouble very easily trying to apply it to multilevel data. There is a critical assumption that you need to ensure is honored, which is that all exchanges you make when generating the null-hypothesis distribution are legitimate exchanges under H0. To state this differently, each randomly re-labeled dataset should be one that could have existed had the experiment gone differently, but didn’t.\nThe functions in {exchangr} are there to help you meet this assumption, but they should not be used without understanding exactly what they do.\n\n\n\n\n\nLet’s see how easy it is to go wrong when exchanging labels on multilevel data. We decide that we want to randomly re-label adults and children in order to test the effect of group and/or the group-by-crit interaction. Run the count() function on the original data in pog_subj to see what is what.\n\npog_subj %>%\n  count(sub_id, group)\n\n# A tibble: 83 × 3\n   sub_id group     n\n   <fct>  <fct> <int>\n 1 1      adult    62\n 2 2      adult    62\n 3 3      adult    62\n 4 4      adult    62\n 5 5      adult    62\n 6 6      adult    62\n 7 7      adult    62\n 8 8      adult    62\n 9 9      adult    62\n10 10     adult    62\n# … with 73 more rows\n\n\nEach subject was either an adult or a child, and has 62 observations. Now let’s imagine we applied shuffle() without thinking, as an attempt to reattach the labels across subjects\n\nset.seed(62) # so you get the same random result as me\n\npog_shuffled_bad <- pog_subj %>%\n  shuffle(group)\n\npog_shuffled_bad\n\n# A tibble: 5,146 × 5\n   sub_id group crit          ms     p\n   <fct>  <fct> <fct>      <int> <dbl>\n 1 1      adult competitor  -200 0.2  \n 2 1      child competitor  -183 0.333\n 3 1      adult competitor  -166 0.467\n 4 1      adult competitor  -150 0.5  \n 5 1      child competitor  -133 0.467\n 6 1      child competitor  -116 0.367\n 7 1      adult competitor  -100 0.3  \n 8 1      child competitor   -83 0.367\n 9 1      adult competitor   -66 0.4  \n10 1      child competitor   -50 0.4  \n# … with 5,136 more rows\n\npog_shuffled_bad %>%\n  count(sub_id, group)\n\n# A tibble: 166 × 3\n   sub_id group     n\n   <fct>  <fct> <int>\n 1 1      adult    33\n 2 1      child    29\n 3 2      adult    37\n 4 2      child    25\n 5 3      adult    28\n 6 3      child    34\n 7 4      adult    21\n 8 4      child    41\n 9 5      adult    38\n10 5      child    24\n# … with 156 more rows\n\n\nSo now we can see the problem: in our re-labeled group, subject 1 is both adult and child! We have violated the exchangeability of the labels under the null hypothesis, creating an impossible dataset, and turning a between-subject factor into a within-subject factor. Any null-hypothesis distribution created from this manner of shuffling will be garbage.\nWhat we need to do is to “nest” the 62 observations into a list-column before we do the shuffling, using the nest() function from {tidyr}. Once we’ve done this, then we can run the shuffle function, and then unnest the data back into it’s original form.\n\n5.2.1 Activity: Build a nest()\nLet’s try using the nest() function to create the data below from pog_subj. For guidance, look at the examples in the documentation (type ?nest in the console). Save the result as pog_nest. Then try to unnest() the data.\n\n\n# A tibble: 83 × 3\n   sub_id group data             \n   <fct>  <fct> <list>           \n 1 1      adult <tibble [62 × 3]>\n 2 2      adult <tibble [62 × 3]>\n 3 3      adult <tibble [62 × 3]>\n 4 4      adult <tibble [62 × 3]>\n 5 5      adult <tibble [62 × 3]>\n 6 6      adult <tibble [62 × 3]>\n 7 7      adult <tibble [62 × 3]>\n 8 8      adult <tibble [62 × 3]>\n 9 9      adult <tibble [62 × 3]>\n10 10     adult <tibble [62 × 3]>\n# … with 73 more rows\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npog_nest <- pog_subj %>%\n  nest(data = c(-sub_id, -group))\n\n\n## back to its original format\npog_nest %>%\n  unnest(cols = c(data))\n\n# A tibble: 5,146 × 5\n   sub_id group crit          ms     p\n   <fct>  <fct> <fct>      <int> <dbl>\n 1 1      adult competitor  -200 0.2  \n 2 1      adult competitor  -183 0.333\n 3 1      adult competitor  -166 0.467\n 4 1      adult competitor  -150 0.5  \n 5 1      adult competitor  -133 0.467\n 6 1      adult competitor  -116 0.367\n 7 1      adult competitor  -100 0.3  \n 8 1      adult competitor   -83 0.367\n 9 1      adult competitor   -66 0.4  \n10 1      adult competitor   -50 0.4  \n# … with 5,136 more rows\n\n\n\n\n\nOK, now that we’ve figured out how to nest data, we can apply shuffle() to the nested data and then unnest. We’ll write a function to do this called shuffle_ml(). This will work with all the {clusterperm} functions as long as we name the first argument .data.\n\nshuffle_ml <- function(.data) {\n  .data %>%\n    nest(data = c(-sub_id, -group)) %>%\n    shuffle(group) %>%\n    unnest(data)\n}\n\nLet’s try it out and verify that it works as intended.\n\npog_subj %>%\n  shuffle_ml() %>%\n  count(sub_id, group)\n\n# A tibble: 83 × 3\n   sub_id group     n\n   <fct>  <fct> <int>\n 1 1      adult    62\n 2 2      child    62\n 3 3      adult    62\n 4 4      adult    62\n 5 5      child    62\n 6 6      adult    62\n 7 7      adult    62\n 8 8      adult    62\n 9 9      adult    62\n10 10     adult    62\n# … with 73 more rows\n\n\nLooks good! Now we are ready to use shuffle_ml() to build our NHD (null-hypothesis distribution). Note that because we are only shuffling group, we can only use the NHD for tests of group and group-by-crit. If we also want to run a test of the main effect of crit, we would have to shuffle crit (and because it’s a mixed design, you’d have to “synchronize” the shuffling over the levels of group, for which shuffle_each_sync() has been provided).\nWe’ll use cluster_nhds() to get our null hypothesis distribution from 1000 monte carlo runs, and then the pvalues() function to derive p-values for our original clusters.\n\n## make sure we're not using an old version\nstopifnot(packageVersion(\"clusterperm\") > \"0.1.0\")\n\n## warning: can take many minutes!!\nset.seed(62) # for reproducibility\nnhds <- cluster_nhds(1000, pog_subj, ms,\n                     p ~ group * crit + Error(sub_id / crit),\n                     shuffle_ml)\n\ncp_result <- pvalues(clusters %>% filter(effect != \"crit\"), \n                     nhds %>% filter(effect != \"crit\"))\n\nsaveRDS(cp_result, \n        file = \"data-derived/cluster-permutation-result.rds\")\n\nNow let’s print out the results.\n\n\n\n\ncp_result\n\n# A tibble: 2 × 6\n  effect        b0    b1  sign   cms        p\n  <chr>      <int> <int> <dbl> <dbl>    <dbl>\n1 group        150   300    -1 169.  0.000999\n2 group:crit    33    66     1  21.5 0.127   \n\n\nWe have a clear main effect of group extending from 150-300 ms, which is where on the figure we can see the adults have a higher probability of looking at either picture than the children (p < .001). There was a group-by-competition interaction detected on the original data from 33-66 ms, but it was not statistically significant (p = 0.127).\n\n\n\n\nBullmore, Edward T, John Suckling, Stephan Overmeyer, Sophia Rabe-Hesketh, Eric Taylor, and Michael J Brammer. 1999. “Global, Voxel, and Cluster Tests, by Theory and Permutation, for a Difference Between Two Groups of Structural MR Images of the Brain.” IEEE Transactions on Medical Imaging 18: 32–42.\n\n\nMaris, Eric, and Robert Oostenveld. 2007. “Nonparametric Statistical Testing of EEG-and MEG-Data.” Journal of Neuroscience Methods 164: 177–90.\n\n\nSassenhagen, Jona, and Dejan Draschkow. 2019. “Cluster-Based Permutation Tests of MEG/EEG Data Do Not Establish Significance of Effect Latency or Location.” Psychophysiology 56: e13335."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Barr, Dale J. 2008. “Analyzing ‘Visual World’\nEyetracking Data Using Multilevel Logistic Regression.”\nJournal of Memory and Language 59: 457–74.\n\n\nBullmore, Edward T, John Suckling, Stephan Overmeyer, Sophia\nRabe-Hesketh, Eric Taylor, and Michael J Brammer. 1999. “Global,\nVoxel, and Cluster Tests, by Theory and Permutation, for a Difference\nBetween Two Groups of Structural MR Images of the Brain.”\nIEEE Transactions on Medical Imaging 18: 32–42.\n\n\nMaris, Eric, and Robert Oostenveld. 2007. “Nonparametric\nStatistical Testing of EEG-and MEG-Data.” Journal of\nNeuroscience Methods 164: 177–90.\n\n\nMirman, Daniel, James A Dixon, and James S Magnuson. 2008. “Statistical and computational models of the visual world\nparadigm: Growth curves and individual differences.”\nJournal of Memory and Language 59 (4): 475–94.\n\n\nSassenhagen, Jona, and Dejan Draschkow. 2019. “Cluster-Based\nPermutation Tests of MEG/EEG Data Do Not Establish Significance of\nEffect Latency or Location.” Psychophysiology 56:\ne13335.\n\n\nWeighall, AR, Lisa-Marie Henderson, DJ Barr, Scott Ashley Cairney, and\nMark Gareth Gaskell. 2017. “Eye-Tracking the Time-Course of Novel\nWord Learning and Lexical Competition in Adults and Children.”\nBrain and Language 167: 13–27."
  },
  {
    "objectID": "data-structure.html",
    "href": "data-structure.html",
    "title": "Appendix A — Structure of Weighall et al. (2017) raw data",
    "section": "",
    "text": "If you have trouble viewing the image below, you can download a PDF version of the figure."
  }
]